\begin{abstract}
  A neural network can be a powerful agent that executes complicate operation(s) on input data, therefore carry out certain tasks. It is possible to exploit such power iteratively, that is to train a network to design/predict parameters for other networks to carry out the tasks. In this paper, we apply this idea on the task of ``3D Shape Generation from a Single Image ". We design a network to predict parameterization (a mapping in the form of other networks) that map from a predefined parameter domain (i.e. the unit sphere surface in our implementation) to target surface of the shape. We propose such network to enable separation of \textit{semantic variation} and \textit{sampling variation} and generic mesh generation with only point sets as ground truth. We evaluate our approach on the ShapeNet (\cite{shapenetdata}) dataset. Our experiment shows that for the objects with surface that is homeomorphic with sphere our network usually generate better results than the state-of-art \cite{PSGN} and our method usually generate worse results for the objects that is not.     
\end{abstract}