\begin{abstract}
  A neural network can be a powerful agent that executes complicate operation(s) on input data, therefore carry out certain tasks. It is possible to exploit such power iteratively, that is to train a network to design/predict parameters for other networks to carry out the tasks. In this paper, we apply this idea on the task of ``3D Shape Generation from a Single Image ". We design a network to predict mappings (in the form of other networks) that map from a predefined parameter domain \footnote{in case of misunderstanding, please note that the \textit{parameter domain} here is not referring to space of network parameters but a predefined surface in the problem of mesh parameterization. In our implementation the \textit{parameter domain} is the surface of unit sphere} to target surface of the shape. We propose such network to enable separation of \textit{semantic variation} and \textit{sampling variation} and to represent the output surface as a spatial distribution. We evaluate our approach on the ShapeNet (\cite{shapenetdata}) dataset and shows that ... 
\end{abstract}