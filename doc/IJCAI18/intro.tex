\section{Introduction}
The problem of point set generation from a single image is a problem of regressing shape with ambiguous input and output spaces. One of ambiguity arises from the fact that 3D-to-2D projection is not invertible and large portions of the shape features are excluded in the input image. We refer to this ambiguity in input space as \textit{semantic variation}. Another ambiguity arises from the fact that we can sample multiple point sets from the same shape and the discrepancy between these samples are not zero under common measurement(e.g. Chamfer Distance used in \cite{PSGN}). We refer to this ambiguity in output space as \textit{sampling variation}. These two kinds of ambiguity was not clearly identified and separated in \cite{PSGN}. Judged by the result shown in \cite{PSGN}, it seems that only some level of \textit{sampling variation} is successfully handled in the network proposed by \cite{PSGN}.

In order to handle these two kinds of ambiguity separately, we use a network to predict parameters for a mapping network that maps the unit sphere surface to the target surface.\footnote{We name the prediction of mapping as ``Parameterization Prediction" for its obvious relation to the mesh parameterization and its potential to actual extend to mesh parameterization problem. However, in this paper we do not pursue bijection mapping as in mesh parameterization since a lot of surface of objects in ShapeNet is not homeomorphic with the sphere surface.} Such network structure can enable the separation of \textit{semantic variation} and \textit{sampling variation} in the way that the \textit{sampling variation} can be explored by sampling different point sets from the parameter domain (i.e. the unit sphere surface), leaving \textit{semantic variation} to be explored by adding random vector to 2D features.

In addition to the separation of \textit{semantic variation} and \textit{sampling variation}, we also propose such network structure to enable the representation of shape as spatial distribution. This perspective is inspired by VAE\cite{VAE} in the sense that a large portion of distribution can be approximated by standard normal distribution plus a learned complicate mapping. In our network, we actually represent the output shape using a spherical uniform distribution plus a predicted complicate mapping. These two combined can represent complicate distribution of surface. Such representation also provide a more complete definition of the surface than the representation as unordered point set. One of the obvious advantage of such representation is that we can generate dense point set even though only trained with sparse point set as ground-truth. This can be done in the runtime by repeating uniform sampling on the parameter domain and concatenate the results as one point set. 

In summary, our contributions are ...             

