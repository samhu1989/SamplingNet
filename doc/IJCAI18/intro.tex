\section{Introduction}
The problem of point set generation from a single image is a problem of regressing shape with ambiguous input and output spaces. One of ambiguity arises from the fact that 3D-to-2D projection is not invertible and large portions of the shape features are excluded in the input image. We refer to this ambiguity in input space as \textit{semantic variation}. Another ambiguity arises from the fact that we can sample multiple point sets from the same shape and the discrepancy between these samples are not zero under common measurement(e.g. Chamfer Distance used in \cite{PSGN}). We refer to this ambiguity in output space as \textit{sampling variation}. These two kinds of ambiguity was not clearly identified and separated in \cite{PSGN}. Judged by the result shown in \cite{PSGN}, it seems that only some level of \textit{sampling variation} is successfully handled in the network proposed by \cite{PSGN}.

In order to handle these two kinds of ambiguity separately, we use a semantic network to predict parameters for a parameterization network that maps the unit sphere surface to the target surface. Such network structure can enable the separation of \textit{semantic variation} and \textit{sampling variation} in the way that the \textit{sampling variation} can be explored by sampling different point sets from the parameter domain (i.e. the unit sphere surface), leaving \textit{semantic variation} to be explored by adding random vector to 2D features.

In addition to the separation of \textit{semantic variation} and \textit{sampling variation}, we also propose such network structure to enable the representation of shape as spatial distribution. This perspective is inspired by VAE\cite{VAE} in the sense that a large portion of distribution can be approximated by standard normal distribution plus a learned complicate mapping. In our network, we actually represent the output shape using a uniform distribution defined on sphere surface plus a predicted complicate mapping. These two combined can represent complicate distribution of surface. Such representation also provide a more complete definition of the surface than the representation as unordered point set. One of the obvious advantage of such representation is that we can generate dense point set even though only trained with sparse point set as ground-truth. Another advantage of such representation is that our network comes with a native mesh generation procedure, we can generate mesh by simply apply the triangulation in parameter domain onto the predicted point set.

In summary, our contributions are
\begin{itemize}
	\item  Introduction of parameterization network that enable dense sampling and native mesh generation by representing the 3D shape as a spherical uniform distribution plus a learned/predicted mapping.
	\item  Exploring the idea that use semantic network to predict parameters for parameterization network. Such structure  relate input image to parameterization network and enable the separation of \textit{semantic variation} and \textit{sampling variation}.
	\item Evaluation of multiple variation of proposed network on ShapeNet\cite{shapenetdata} comparing to \cite{PSGN}. Making practical plan for future steps towards a actual useful ``parameterization prediction" network based on issues demonstrated in the result.
\end{itemize}          

